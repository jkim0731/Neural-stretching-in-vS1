{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same as 221024_build_dataset.ipynb\n",
    "- Organized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, shutil, tqdm, glob, h5py, mat73, imageio, napari\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from tqdm import notebook\n",
    "\n",
    "# h5_dir_1 = Path(r'C:\\Users\\shires\\Dropbox\\Works\\Projects\\2020 Neural stretching in S1\\Data\\h5')\n",
    "# h5_dir_2 = Path(r'C:\\Users\\shires\\Dropbox\\Works\\Projects\\2020 Neural stretching in S1\\Data\\h5')\n",
    "h5_dir = Path('E:\\TPM\\JK\\h5')\n",
    "b_dir = Path('H:/SoloData/')\n",
    "w_dir = Path('H:/WhiskerVideo/')\n",
    "mice =          [25,    27,   30,   36,     37,     38,     39,     41,     52,     53,     54,     56]\n",
    "# refSessions =   [4,     3,    3,    1,      7,      2,      1,      3,      3,      3,      3,      3]\n",
    "# expSessions =   [19,    10,   21,   17,     0,      0,      23,     0,      21,     0,      0,      0]\n",
    "# zoom =          [2,     2,    2,    1.7,    1.7,    1.7,    1.7,    1.7,    1.7,    1.7,    1.7,    1.7]\n",
    "image_rate_list = [30.8359, 30.8359, 30.8359, 30.8359, \n",
    "                    24.2892, 24.2892, 24.2892, 24.2892,\n",
    "                    30.8359, 30.8359, 30.8359, 30.8359] # from .mat file (sbx)\n",
    "image_size_list = [[512,796], [512,796], [512,796], [512,796], \n",
    "                    [650,796], [650,796], [650,796], [650,796], \n",
    "                    [512,796], [512,796], [512,796], [512,796]] # from .mat file (sbx)\n",
    "\n",
    "planes = range(1,9)\n",
    "\n",
    "# mice =          [25,    27,   30,   36,     39,     52]\n",
    "# refSessions =   [4,     3,    3,    1,      1,      3]\n",
    "# expSessions =   [19,    10,   21,   17,     23,     21]\n",
    "# zoom =          [2,     2,    2,    1.7,    1.7,    1.7]\n",
    "# freq =          [7.7,   7.7,  7.7,  7.7,    6.1,    7.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making whisker pkl files\n",
    "- Done for all 12 mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in notebook.tqdm(mice):\n",
    "    session_folder_list = glob.glob(str(w_dir / f'JK{mouse:03d}S*'))\n",
    "    for session_folder in notebook.tqdm(session_folder_list):\n",
    "        session_name = session_folder.split('\\\\')[-1]\n",
    "        wf_fn = w_dir / session_name / f'{session_name}_whisker_final_h5.mat'\n",
    "        whisker_pkl_fn = w_dir / session_name / f'{session_name}_whisker.pkl'\n",
    "        # if not os.path.isfile(whisker_pkl_fn):\n",
    "        if os.path.isfile(wf_fn):\n",
    "            w_data = mat73.loadmat(wf_fn)\n",
    "            dict_keys = list(w_data['hw']['trials'][1].keys())\n",
    "            whisker_df = pd.DataFrame(columns=dict_keys)\n",
    "            num_trials = len(w_data['hw']['trials'])\n",
    "            for i in range(num_trials):\n",
    "                trial_data = w_data['hw']['trials'][i]\n",
    "                trial_df = pd.DataFrame({})\n",
    "                for key in dict_keys:\n",
    "                    trial_df[key] = [trial_data[key]]\n",
    "                whisker_df = whisker_df.append(trial_df)\n",
    "            whisker_df['mouse_name'] = w_data['hw']['mouse_name']\n",
    "            whisker_df['session_name'] = w_data['hw']['session_name']\n",
    "            whisker_df.rename(columns={'time': 'whisker_time'}, inplace=True)\n",
    "            whisker_df['trialNum'] = whisker_df['trialNum'].astype(int)\n",
    "            whisker_df['poleAngle'] = whisker_df['poleAngle'].astype(int)\n",
    "            whisker_df['poleDistance'] = whisker_df['poleDistance'].astype(int)\n",
    "            whisker_df.set_index('trialNum', inplace=True)\n",
    "            whisker_df.to_pickle(whisker_pkl_fn)\n",
    "# All mice takes about 3 hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making behavior pkl files\n",
    "- Done for all 12 mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in notebook.tqdm(mice):\n",
    "    b_fn = b_dir / f'JK{mouse:03d}' / f'behavior_JK{mouse:03d}_h5.mat'\n",
    "    if os.path.isfile(b_fn):\n",
    "        behavior_data = mat73.loadmat(b_fn)\n",
    "\n",
    "        num_sessions = len(behavior_data['hb']['sessions'])\n",
    "        mouse_name = behavior_data['hb']['mouse_name']\n",
    "        for si in range(num_sessions):\n",
    "            session_name = behavior_data['hb']['sessions'][si]['sessionName']\n",
    "            if 'pre' in session_name:\n",
    "                pre_session_num = session_name.split('pre')[1]\n",
    "                session_name = f'S9{pre_session_num}'\n",
    "            b_session_pkl_fn = b_dir / f'JK{mouse:03d}' / f'{mouse_name}{session_name}_behavior.pkl'\n",
    "            # if not os.path.isfile(b_session_pkl_fn):\n",
    "            keys = list(behavior_data['hb']['sessions'][si]['trials'][0].keys())    \n",
    "            b_df = pd.DataFrame(columns=keys)\n",
    "            num_trials = len(behavior_data['hb']['sessions'][si]['trials'])\n",
    "            for ti in range(num_trials):\n",
    "                trial_data = behavior_data['hb']['sessions'][si]['trials'][ti]\n",
    "                trial_df = pd.DataFrame({})\n",
    "                for key in keys:\n",
    "                    trial_df[key] = [trial_data[key]]\n",
    "                    if key == 'answerLickTime':\n",
    "                        if np.size(trial_data[key])==2:\n",
    "                            trial_df[key] = 0\n",
    "                    if key == 'beamBreakTimesLeft' or 'beamBreakTimesRight':\n",
    "                        if np.size(trial_data[key])==1:\n",
    "                            trial_df[key] = np.asarray(np.array([[trial_data[key]]]))\n",
    "                        elif (len(trial_data[key]) == 2 ) and (trial_data[key][0]==0) and (trial_data[key][1]==1):\n",
    "                            trial_df[key] = np.asarray(np.array([0]))\n",
    "                b_df = b_df.append(trial_df)\n",
    "            b_df['mouse_name'] = mouse_name\n",
    "            b_df['session_name'] = behavior_data['hb']['sessions'][si]['sessionName']\n",
    "            b_df['session_type'] = behavior_data['hb']['sessions'][si]['sessionType']\n",
    "            b_df['task_target'] = behavior_data['hb']['sessions'][si]['taskTarget']\n",
    "            b_df['distractor'] = behavior_data['hb']['sessions'][si]['distractor']\n",
    "            b_df['trialNum'] = b_df['trialNum'].astype(int)\n",
    "            b_df['servoAngle'] = b_df['servoAngle'].astype(int)\n",
    "            b_df['motorDistance'] = b_df['motorDistance'].astype(int)\n",
    "            b_df['motorApPosition'] = b_df['motorApPosition'].astype(int)\n",
    "            b_df.set_index('trialNum', inplace=True)\n",
    "\n",
    "            b_df.to_pickle(b_session_pkl_fn)\n",
    "# All mice takes about 63 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior pkl file QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all mice and sessions automatically\n",
    "for mouse in mice:\n",
    "    b_fn = b_dir / f'JK{mouse:03d}' / f'behavior_JK{mouse:03d}_h5.mat'\n",
    "    behavior_data = mat73.loadmat(b_fn)\n",
    "    \n",
    "    num_sessions = len(behavior_data['hb']['sessions'])\n",
    "    mouse_name = behavior_data['hb']['mouse_name']\n",
    "    for si in range(num_sessions):\n",
    "        mat_trial_nums = np.array([trial['trialNum'] for trial in behavior_data['hb']['sessions'][si]['trials']])\n",
    "        session_name = behavior_data['hb']['sessions'][si]['sessionName']\n",
    "        if 'pre' in session_name:\n",
    "            pre_session_num = session_name.split('pre')[1]\n",
    "            session_name = f'S9{pre_session_num}'\n",
    "        b_session_pkl_fn = b_dir / f'JK{mouse:03d}' / f'{mouse_name}{session_name}_behavior.pkl'\n",
    "\n",
    "        b_df = pd.read_pickle(b_session_pkl_fn)\n",
    "        pkl_trial_nums = b_df.index.values\n",
    "\n",
    "        if not np.array_equiv(mat_trial_nums, pkl_trial_nums):\n",
    "            print(f'Error in {mouse_name} {session_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write pkl files for 2p frame times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_mice_ind = [0,1,2,3,6,8]\n",
    "\n",
    "for emi in range(3,6):\n",
    "    mi = expert_mice_ind[emi]\n",
    "    # if emi < 3:\n",
    "    #     h5_dir = h5_dir_1\n",
    "    # else:\n",
    "    #     h5_dir = h5_dir_2\n",
    "    mouse = mice[mi]\n",
    "    image_rate = image_rate_list[mi]\n",
    "    image_size = image_size_list[mi]\n",
    "\n",
    "    for top_plane_ind in [0,4]:\n",
    "        plane = planes[top_plane_ind]\n",
    "        plane_dir = h5_dir / f'{mouse:03d}' / f'plane_{plane}'\n",
    "        sts_reg = np.load(plane_dir / f'JK{mouse:03d}_plane{plane}_session_to_session_registration.npy', allow_pickle=True).item()\n",
    "        session_nums = sts_reg['selected_session_num']\n",
    "        # This info is valid in pi:pi+4\n",
    "\n",
    "        for session_num in session_nums:\n",
    "            trial_start_end = []\n",
    "            plane_frames = [[],[],[],[]] # 4 planes per volume\n",
    "            ophys_trial_fn_list = glob.glob(str(h5_dir / f'{mouse:03d}' / f'{mouse:03d}_{session_num:03d}_0*.trials')) # sometimes there are multiple trials files because of random scanbox stoppage error\n",
    "            for fn in ophys_trial_fn_list:\n",
    "                ophys_trial = loadmat(fn, simplify_cells=True)\n",
    "                trial_start_end.extend(ophys_trial['trials'])\n",
    "                for pi in range(4):\n",
    "                    plane_frames[pi].extend(ophys_trial['frame_to_use'][top_plane_ind+pi])\n",
    "\n",
    "            #############################################        \n",
    "            # Exception to handle I/O error from BControl\n",
    "            if (mouse == 27) and (session_num == 12):\n",
    "                trial_start_end = trial_start_end[:-1]\n",
    "\n",
    "            plane_df_list = [pd.DataFrame(columns=['trialNum', 'frame_start_time', 'frame_end_time', 'trial_duration', 'frame_index']), # trial_duration for trial length QC\n",
    "                            pd.DataFrame(columns=['trialNum', 'frame_start_time', 'frame_end_time', 'trial_duration', 'frame_index']),\n",
    "                            pd.DataFrame(columns=['trialNum', 'frame_start_time', 'frame_end_time', 'trial_duration', 'frame_index']),\n",
    "                            pd.DataFrame(columns=['trialNum', 'frame_start_time', 'frame_end_time', 'trial_duration', 'frame_index'])]\n",
    "            for trial in trial_start_end:\n",
    "                trial_num = trial['trialnum']\n",
    "                if np.isfinite(trial_num): # there was a case where trialnum was NaN, and corresponding frames were > 2000 frames in len\n",
    "                    # Happened only in 025_006_000.trials (d230104_trial_num_nan_check.m)\n",
    "                    # Not checked for non-experts.\n",
    "                    # Add frame index (index of frame_to_use)\n",
    "                    # Does not need to remove corresponding frames from calcium data, because frame_to_use were collected by matching 'trialnum', so\n",
    "                    # 'NaN' trialnum were not assigned.\n",
    "                    # Thus, total # of rows in the dataframe matches to the last frame index.\n",
    "                    trial_start_frame = trial['frames'][0]\n",
    "                    trial_end_frame = trial['frames'][1]\n",
    "                    trial_start_line = trial['lines'][0] # 1-based index from MATLAB, not 0-based index\n",
    "                    trial_end_line = trial['lines'][1]\n",
    "                    # Find indice for this trial from the plane\n",
    "                    plane_frame_inds_trial = []\n",
    "                    for pi in range(4):\n",
    "                        plane_frame_inds_trial.append(np.where((plane_frames[pi] >= trial['frames'][0]) & (plane_frames[pi] <= trial['frames'][1]))[0].astype(int))\n",
    "                    len_frames = np.array([len(f) for f in plane_frame_inds_trial])\n",
    "                    assert (len_frames[1:] - len_frames[0]).any() == False # to confirm that each plane shared the same # of frames\n",
    "\n",
    "                    # Make per trial DataFrame in each plane\n",
    "                    for pi in range(4):\n",
    "                        # Calculate start and end time for each frame\n",
    "                        plane_frame_trial = np.asarray(plane_frames[pi])[plane_frame_inds_trial[pi]]\n",
    "                        start_tmp = list((plane_frame_trial - trial_start_frame + (trial_start_line - 1) / image_size[0]) / image_rate)\n",
    "                        end_tmp = list((plane_frame_trial - trial_start_frame + 1 + (trial_start_line - 1) / image_size[0]) / image_rate) #\n",
    "                            # end_time should include the end of the last line \n",
    "                            # It matches to the next frame (next plane) start time\n",
    "                            # TTL signal is assumed to have arrived at the beginning of the line\n",
    "                        trial_df_tmp = pd.DataFrame()\n",
    "                        trial_df_tmp['frame_start_time'] = start_tmp\n",
    "                        trial_df_tmp['frame_end_time'] = end_tmp\n",
    "                        trial_df_tmp['trialNum'] = trial_num\n",
    "                        # Calculate trial duration\n",
    "                        trial_duration = (trial_end_frame - trial_start_frame + (trial_end_line - trial_start_line) / image_size[0]) / image_rate\n",
    "                        trial_df_tmp['trial_duration'] = trial_duration\n",
    "                        trial_df_tmp['frame_index'] = plane_frame_inds_trial[pi]\n",
    "\n",
    "                        plane_df_list[pi] = plane_df_list[pi].append(trial_df_tmp)\n",
    "            # Reset index for all the frames and save to pkl file\n",
    "            for pi in range(4):\n",
    "                plane_df_list[pi].reset_index(drop=True, inplace=True)\n",
    "                plane = planes[top_plane_ind+pi]\n",
    "                plane_dir= h5_dir / f'{mouse:03d}' / f'plane_{plane}' \n",
    "                pkl_fn =  f'{mouse:03d}_{session_num:03d}_plane_{plane}_frame_time.pkl'\n",
    "                plane_df_list[pi].to_pickle(plane_dir / pkl_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC 2p time frame pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC by comparing trial nums between pkl file and .trials file\n",
    "mouse = 27\n",
    "session_num = 3\n",
    "plane = 5\n",
    "\n",
    "ophys_trial_fn_list = glob.glob(str(h5_dir / f'{mouse:03d}' / f'{mouse:03d}_{session_num:03d}_0*.trials')) # sometimes there are multiple trials files because of random scanbox stoppage error\n",
    "trial_start_end = []\n",
    "plane_frames = [[],[],[],[]]\n",
    "layer_trials = np.zeros(1,)\n",
    "for fn in ophys_trial_fn_list:\n",
    "    ophys_trial = loadmat(fn, simplify_cells=True)\n",
    "    if plane < 5:\n",
    "        layer_trials = np.concatenate((layer_trials, ophys_trial['layer_trials'][0]))\n",
    "    else:\n",
    "        layer_trials = np.concatenate((layer_trials, ophys_trial['layer_trials'][1]))\n",
    "    trial_start_end.extend(ophys_trial['trials'])\n",
    "    for pi in range(4):\n",
    "        plane_frames[pi].extend(ophys_trial['frame_to_use'][top_plane_ind+pi])\n",
    "\n",
    "plane_dir= h5_dir / f'{mouse:03d}' / f'plane_{plane}' \n",
    "pkl_fn =  f'{mouse:03d}_{session_num:03d}_plane_{plane}_frame_time.pkl'\n",
    "frame_time_df = pd.read_pickle(plane_dir / pkl_fn)\n",
    "\n",
    "trial_num_pkl = frame_time_df.trialNum.unique()\n",
    "print(np.setdiff1d(trial_num_pkl, layer_trials))\n",
    "print(np.setdiff1d(layer_trials, trial_num_pkl))\n",
    "print(layer_trials[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_whisker_to_frame_df(frame_time_df, whisker_df):\n",
    "    # Initialization\n",
    "    # touch onset features\n",
    "    kappaH_onset = np.empty(len(frame_time_df))\n",
    "    kappaH_onset[:] = np.nan\n",
    "    kappaV_onset = np.empty(len(frame_time_df))\n",
    "    kappaV_onset[:] = np.nan\n",
    "    phi_onset = np.empty(len(frame_time_df))\n",
    "    phi_onset[:] = np.nan\n",
    "    theta_onset = np.empty(len(frame_time_df))\n",
    "    theta_onset[:] = np.nan\n",
    "    arc_length_onset = np.empty(len(frame_time_df))\n",
    "    arc_length_onset[:] = np.nan\n",
    "    touch_count = np.empty(len(frame_time_df))\n",
    "    touch_count[:] = np.nan\n",
    "    # during touch features\n",
    "    delta_kappaH = np.empty(len(frame_time_df))\n",
    "    delta_kappaH[:] = np.nan\n",
    "    delta_kappaV = np.empty(len(frame_time_df))\n",
    "    delta_kappaV[:] = np.nan\n",
    "    delta_phi = np.empty(len(frame_time_df))\n",
    "    delta_phi[:] = np.nan\n",
    "    delta_theta = np.empty(len(frame_time_df))\n",
    "    delta_theta[:] = np.nan\n",
    "    slide_distance = np.empty(len(frame_time_df))\n",
    "    slide_distance[:] = np.nan\n",
    "    touch_duration = np.empty(len(frame_time_df))\n",
    "    touch_duration[:] = np.nan\n",
    "    # pole frame\n",
    "    pole_up_frame = np.zeros(len(frame_time_df))\n",
    "    pole_moving_frame = np.zeros(len(frame_time_df))\n",
    "\n",
    "    trial_nums = frame_time_df.trialNum.unique()\n",
    "    whisker_empty_trial_nums = []\n",
    "    for trial_num in trial_nums:\n",
    "        # 2p frame index and time\n",
    "        trial_2p_index = np.where(frame_time_df.trialNum==trial_num)[0]\n",
    "        trial_2p_time = frame_time_df.frame_end_time.values[trial_2p_index] # end-to-end frame allocation\n",
    "        # First frame can be quite long, but there is no way that touch happened on the first frame\n",
    "        # whisker touch time\n",
    "        trial_whisker_series = whisker_df[whisker_df.index==trial_num]\n",
    "\n",
    "        if len(trial_whisker_series) == 0: # No whisker processing (or error in the video, etc.)\n",
    "            whisker_empty_trial_nums.append(trial_num)\n",
    "        else:\n",
    "            trial_whisker_time = trial_whisker_series.whisker_time.values[0]\n",
    "\n",
    "            trial_kappaH = trial_whisker_series.kappaH.values[0]\n",
    "            trial_kappaV = trial_whisker_series.kappaV.values[0]\n",
    "            trial_phi = trial_whisker_series.phi.values[0]\n",
    "            trial_theta = trial_whisker_series.theta.values[0]\n",
    "            trial_arc_length = trial_whisker_series.arcLength.values[0]\n",
    "\n",
    "            trial_protraction_touch_chunks = trial_whisker_series.protractionTFchunksByWhisking.values[0] # when touch frame chunks by whisking were used\n",
    "            # trial_protraction_touch_chunks = trial_whisker_series.protractionTFchunks.values[0] # in case when touch frame chunks were used\n",
    "            if len(trial_protraction_touch_chunks)>0:\n",
    "                assert len(trial_protraction_touch_chunks) == len(trial_whisker_series.protractionSlideByWhisking.values[0])\n",
    "                # touch_onset_times = [trial_whisker_time[touch_chunks[0].astype(int)-1] for touch_chunks in trial_protraction_touch_chunks]\n",
    "                for touch_ind, touch_chunk_whisker_index in enumerate(trial_protraction_touch_chunks):\n",
    "                    if np.ndim(touch_chunk_whisker_index) == 0:\n",
    "                        touch_chunk_whisker_index = np.asarray([touch_chunk_whisker_index])\n",
    "                    touch_chunk_whisker_index = touch_chunk_whisker_index.astype(int)-1 # correcting 1-based MATLAB index to 0-based python index\n",
    "                    touch_onset_time = trial_whisker_time[touch_chunk_whisker_index[0]]\n",
    "                    touch_onset_2p_index = np.where(trial_2p_time>touch_onset_time)[0][0]\n",
    "\n",
    "                    # Assign touch onset features\n",
    "                    kappaH_first = trial_kappaH[touch_chunk_whisker_index[0]]\n",
    "                    kappaV_first = trial_kappaV[touch_chunk_whisker_index[0]]\n",
    "                    phi_first = trial_phi[touch_chunk_whisker_index[0]]\n",
    "                    theta_first = trial_theta[touch_chunk_whisker_index[0]]\n",
    "\n",
    "                    if np.isnan(kappaH_onset[trial_2p_index[touch_onset_2p_index]]):\n",
    "                        kappaH_onset[trial_2p_index[touch_onset_2p_index]] = kappaH_first \n",
    "                    else:\n",
    "                        kappaH_onset[trial_2p_index[touch_onset_2p_index]] += kappaH_first \n",
    "                    if np.isnan(kappaV_onset[trial_2p_index[touch_onset_2p_index]]):\n",
    "                        kappaV_onset[trial_2p_index[touch_onset_2p_index]] = kappaV_first\n",
    "                    else:\n",
    "                        kappaV_onset[trial_2p_index[touch_onset_2p_index]] += kappaV_first\n",
    "                    if np.isnan(phi_onset[trial_2p_index[touch_onset_2p_index]]):\n",
    "                        phi_onset[trial_2p_index[touch_onset_2p_index]] = phi_first\n",
    "                    else:\n",
    "                        phi_onset[trial_2p_index[touch_onset_2p_index]] += phi_first\n",
    "                    if np.isnan(theta_onset[trial_2p_index[touch_onset_2p_index]]):\n",
    "                        theta_onset[trial_2p_index[touch_onset_2p_index]] = theta_first\n",
    "                    else:\n",
    "                        theta_onset[trial_2p_index[touch_onset_2p_index]] += theta_first\n",
    "                    \n",
    "                    if np.isnan(arc_length_onset[trial_2p_index[touch_onset_2p_index]]):\n",
    "                        arc_length_onset[trial_2p_index[touch_onset_2p_index]] = trial_arc_length[touch_chunk_whisker_index[0]]\n",
    "                    else:\n",
    "                        arc_length_onset[trial_2p_index[touch_onset_2p_index]] += trial_arc_length[touch_chunk_whisker_index[0]]\n",
    "                    if np.isnan(touch_count[trial_2p_index[touch_onset_2p_index]]):\n",
    "                        touch_count[trial_2p_index[touch_onset_2p_index]] = 1\n",
    "                    else:\n",
    "                        touch_count[trial_2p_index[touch_onset_2p_index]] += 1\n",
    "\n",
    "                    # Assign during touch features\n",
    "                    touch_offset_time = trial_whisker_time[touch_chunk_whisker_index[-1]]\n",
    "                    touch_offset_2p_index = np.where(trial_2p_time>touch_offset_time)[0][0]\n",
    "                    slide_distance_trial = trial_whisker_series.protractionSlideByWhisking.values[0][touch_ind]\n",
    "                    if np.ndim(slide_distance_trial) == 0:\n",
    "                        slide_distance_trial = np.asarray([slide_distance_trial])\n",
    "                    for touch_2p_index in range(touch_onset_2p_index,touch_offset_2p_index+1):\n",
    "                        # kappaH, kappaV, phi, theta, requires calculating max values within the frame, compared to the first value\n",
    "                        current_2p_frame_end_time = trial_2p_time[touch_2p_index]\n",
    "                        if trial_whisker_time[touch_chunk_whisker_index[-1]] > current_2p_frame_end_time: # when the current touch chunk ends later than the current 2p frame end time\n",
    "                            last_whisker_index_within_frame = np.where(trial_whisker_time[touch_chunk_whisker_index] > current_2p_frame_end_time)[0][0] # excluding this index\n",
    "                        else:\n",
    "                            last_whisker_index_within_frame = len(touch_chunk_whisker_index) # excluding this index\n",
    "                        \n",
    "                        kappaH_within_frame = trial_kappaH[touch_chunk_whisker_index[:last_whisker_index_within_frame]]\n",
    "                        if np.isnan(delta_kappaH[trial_2p_index[touch_2p_index]]):\n",
    "                            delta_kappaH[trial_2p_index[touch_2p_index]] = np.amin(kappaH_within_frame - kappaH_first) # For protraction touch, only negative values are allowed\n",
    "                        else:\n",
    "                            delta_kappaH[trial_2p_index[touch_2p_index]] += np.amin(kappaH_within_frame - kappaH_first)\n",
    "\n",
    "                        kappaV_within_frame = trial_kappaV[touch_chunk_whisker_index[:last_whisker_index_within_frame]]\n",
    "                        if np.isnan(delta_kappaV[trial_2p_index[touch_2p_index]]):\n",
    "                            delta_kappaV[trial_2p_index[touch_2p_index]] = np.amax(np.abs(kappaV_within_frame - kappaV_first)) * np.sign(kappaV_within_frame[np.argmax(np.abs(kappaV_within_frame - kappaV_first))] - kappaV_first)\n",
    "                        else:\n",
    "                            delta_kappaV[trial_2p_index[touch_2p_index]] += np.amax(np.abs(kappaV_within_frame - kappaV_first)) * np.sign(kappaV_within_frame[np.argmax(np.abs(kappaV_within_frame - kappaV_first))] - kappaV_first)\n",
    "\n",
    "                        phi_within_frame = trial_phi[touch_chunk_whisker_index[:last_whisker_index_within_frame]]\n",
    "                        if np.isnan(delta_phi[trial_2p_index[touch_2p_index]]):\n",
    "                            delta_phi[trial_2p_index[touch_2p_index]] = np.amax(np.abs(phi_within_frame - phi_first)) * np.sign(phi_within_frame[np.argmax(np.abs(phi_within_frame - phi_first))] - phi_first)\n",
    "                        else:\n",
    "                            delta_phi[trial_2p_index[touch_2p_index]] += np.amax(np.abs(phi_within_frame - phi_first)) * np.sign(phi_within_frame[np.argmax(np.abs(phi_within_frame - phi_first))] - phi_first)\n",
    "                        \n",
    "                        theta_within_frame = trial_theta[touch_chunk_whisker_index[:last_whisker_index_within_frame]]\n",
    "                        if np.isnan(delta_theta[trial_2p_index[touch_2p_index]]):\n",
    "                            delta_theta[trial_2p_index[touch_2p_index]] = np.amax(theta_within_frame - theta_first) # For protraction touch, only positive values are allowed\n",
    "                        else:\n",
    "                            delta_theta[trial_2p_index[touch_2p_index]] += np.amax(theta_within_frame - theta_first)\n",
    "\n",
    "                        # Slide distance already calculated per whisker time frame, so only requires calculating max values within the frame\n",
    "                        slide_distance_within_frame = slide_distance_trial[:last_whisker_index_within_frame]\n",
    "                        if np.isnan(slide_distance[trial_2p_index[touch_2p_index]]):\n",
    "                            slide_distance[trial_2p_index[touch_2p_index]] = np.amax(slide_distance_within_frame)\n",
    "                        else:\n",
    "                            slide_distance[trial_2p_index[touch_2p_index]] += np.amax(slide_distance_within_frame)\n",
    "\n",
    "                        # Touch duration\n",
    "                        if np.isnan(touch_duration[trial_2p_index[touch_2p_index]]):\n",
    "                            touch_duration[trial_2p_index[touch_2p_index]] = trial_whisker_time[touch_chunk_whisker_index[last_whisker_index_within_frame-1]] - touch_onset_time\n",
    "                        else:\n",
    "                            touch_duration[trial_2p_index[touch_2p_index]] += trial_whisker_time[touch_chunk_whisker_index[last_whisker_index_within_frame-1]] - touch_onset_time\n",
    "            # Adding pole-up frames and pole-moving frames\n",
    "            pole_moving_time = trial_whisker_time[trial_whisker_series.poleMovingFrames.values[0].astype(int)-1]\n",
    "            pole_up_time = trial_whisker_time[trial_whisker_series.poleUpFrames.values[0].astype(int)-1]\n",
    "            pole_up_2p_frame_first_ind = np.where(trial_2p_time > pole_up_time[0])[0][0]\n",
    "            if len(np.where(trial_2p_time > pole_up_time[-1])[0]) > 0:\n",
    "                pole_up_2p_frame_last_ind = np.where(trial_2p_time > pole_up_time[-1])[0][0]\n",
    "            else:\n",
    "                pole_up_2p_frame_last_ind = len(trial_2p_time)-1\n",
    "            pole_up_frame[trial_2p_index[pole_up_2p_frame_first_ind:pole_up_2p_frame_last_ind+1]] = 1\n",
    "            \n",
    "            pole_moving_2p_frame_first_ind = np.where(trial_2p_time > pole_moving_time[0])[0][0]\n",
    "            pole_moving_frame[trial_2p_index[pole_moving_2p_frame_first_ind:pole_up_2p_frame_first_ind]] = 1\n",
    "\n",
    "            if pole_moving_time[-1] > pole_up_time[-1]: # only when pole moving happened also after pole up\n",
    "                if len(np.where(trial_2p_time > pole_moving_time[-1])[0]) > 0:\n",
    "                    pole_moving_2p_frame_last_ind = np.where(trial_2p_time > pole_moving_time[-1])[0][0]\n",
    "                    pole_moving_frame[trial_2p_index[pole_up_2p_frame_last_ind+1:pole_moving_2p_frame_last_ind+1]] = 1\n",
    "\n",
    "    # Adding whisker features to frame time DataFrame\n",
    "    frame_time_df['kappaH_onset'] = kappaH_onset\n",
    "    frame_time_df['kappaV_onset'] = kappaV_onset\n",
    "    frame_time_df['phi_onset'] = phi_onset\n",
    "    frame_time_df['theta_onset'] = theta_onset\n",
    "    frame_time_df['arc_length_onset'] = arc_length_onset\n",
    "    frame_time_df['touch_count'] = touch_count\n",
    "    frame_time_df['delta_kappaH'] = delta_kappaH\n",
    "    frame_time_df['delta_kappaV'] = delta_kappaV\n",
    "    frame_time_df['delta_phi'] = delta_phi\n",
    "    frame_time_df['delta_theta'] = delta_theta\n",
    "    frame_time_df['slide_distance'] = slide_distance\n",
    "    frame_time_df['touch_duration'] = touch_duration\n",
    "\n",
    "    frame_time_df['pole_up_frame'] = pole_up_frame\n",
    "    frame_time_df['pole_moving_frame'] = pole_moving_frame\n",
    "\n",
    "    # Remove frames from trial_num that had error in whisker processing\n",
    "    frame_time_df = frame_time_df[~np.isin(frame_time_df.trialNum.values, np.asarray(whisker_empty_trial_nums))]\n",
    "\n",
    "    return frame_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_behavior_to_frame_df(frame_time_df, behavior_df):\n",
    "    # Initialize\n",
    "    pole_angle = np.zeros(len(frame_time_df), dtype=np.uint16)\n",
    "    pole_ap_distance = np.zeros(len(frame_time_df), dtype=np.uint32)\n",
    "    pole_radial_distance = np.zeros(len(frame_time_df), dtype=np.uint32)\n",
    "    first_lick_frame = np.zeros(len(frame_time_df), dtype=bool)\n",
    "    first_lick_left = np.zeros(len(frame_time_df), dtype=bool) # if first lick is right, then 0\n",
    "    first_lick_right = np.zeros(len(frame_time_df), dtype=bool) # if first lick is left, then 0\n",
    "    num_lick_left = np.zeros(len(frame_time_df), dtype=np.uint8)\n",
    "    num_lick_right = np.zeros(len(frame_time_df), dtype=np.uint8)\n",
    "    answer_lick_frame = np.zeros(len(frame_time_df), dtype=bool)\n",
    "    answer_lick_left = np.zeros(len(frame_time_df), dtype=bool) # if answer lick is right, then 0\n",
    "    answer_lick_right = np.zeros(len(frame_time_df), dtype=bool) # if answer lick is left, then 0\n",
    "    pre_answer_pole_up_frame = np.zeros(len(frame_time_df), dtype=bool)\n",
    "    answer_period_frame = np.zeros(len(frame_time_df), dtype=bool)\n",
    "    post_answer_pole_up_frame = np.zeros(len(frame_time_df), dtype=bool)\n",
    "    first_reward_lick_frame = np.zeros(len(frame_time_df), dtype=bool)\n",
    "    first_reward_lick_left = np.zeros(len(frame_time_df), dtype=bool) # if first reward lick is right, then 0\n",
    "    first_reward_lick_right = np.zeros(len(frame_time_df), dtype=bool) # if first reward lick is left, then 0\n",
    "    correct = np.zeros(len(frame_time_df), dtype=bool)\n",
    "    wrong = np.zeros(len(frame_time_df), dtype=bool)\n",
    "    miss = np.zeros(len(frame_time_df), dtype=bool)\n",
    "    trial_type = []\n",
    "    task_target = []\n",
    "    distractor = []\n",
    "\n",
    "    trial_nums = frame_time_df.trialNum.unique()\n",
    "    for trial_num in trial_nums:\n",
    "        # 2p frame index and time\n",
    "        trial_2p_index = np.where(frame_time_df.trialNum==trial_num)[0]\n",
    "        trial_2p_time = frame_time_df.frame_end_time.values[trial_2p_index] # end-to-end frame allocation\n",
    "\n",
    "        assert sum(behavior_df.index == trial_num)==1\n",
    "        trial_behavior_series = behavior_df[behavior_df.index==trial_num].iloc[0]\n",
    "        pole_angle[trial_2p_index] = trial_behavior_series.servoAngle\n",
    "        pole_ap_distance[trial_2p_index] = trial_behavior_series.motorApPosition\n",
    "        pole_radial_distance[trial_2p_index] = trial_behavior_series.motorDistance\n",
    "        trial_type.extend([trial_behavior_series.trialType]*len(trial_2p_index))\n",
    "        task_target.extend([trial_behavior_series.task_target]*len(trial_2p_index))\n",
    "        distractor.extend([trial_behavior_series.distractor]*len(trial_2p_index))\n",
    "\n",
    "        lick_times = np.empty(0,)\n",
    "        left_lick_times = trial_behavior_series.beamBreakTimesLeft\n",
    "        if np.size(left_lick_times)==1:\n",
    "            left_lick_times = np.array([left_lick_times])    \n",
    "        right_lick_times = trial_behavior_series.beamBreakTimesRight\n",
    "        if np.size(right_lick_times)==1:\n",
    "            right_lick_times = np.array([right_lick_times])\n",
    "        answer_lick_time = trial_behavior_series.answerLickTime\n",
    "        if answer_lick_time != 0: # answer trial\n",
    "            if (answer_lick_time not in left_lick_times) and (answer_lick_time not in right_lick_times): # In some rare cases\n",
    "                if trial_behavior_series.choice == 'r':\n",
    "                    right_lick_times = np.union1d(answer_lick_time, right_lick_times)\n",
    "                elif trial_behavior_series.choice == 'l':\n",
    "                    left_lick_times = np.union1d(answer_lick_time, left_lick_times)\n",
    "                else:\n",
    "                    raise('When the answer lick time is not 0, there must have been either r or l choice.')\n",
    "\n",
    "        if not ((np.size(left_lick_times)==1) and (np.array(left_lick_times==[0]))):\n",
    "            lick_times = np.hstack((lick_times,left_lick_times))\n",
    "            for left_lick_time in left_lick_times:\n",
    "                if left_lick_time < trial_2p_time[-1]:\n",
    "                    left_lick_frame_ind = np.where(trial_2p_time > left_lick_time)[0][0]\n",
    "                    num_lick_left[trial_2p_index[left_lick_frame_ind]] += 1\n",
    "\n",
    "        if not ((np.size(right_lick_times)==1) and (np.array(right_lick_times==[0]))):\n",
    "            lick_times = np.hstack((lick_times,right_lick_times))\n",
    "            for right_lick_time in right_lick_times:\n",
    "                if right_lick_time < trial_2p_time[-1]:\n",
    "                    right_lick_frame_ind = np.where(trial_2p_time > right_lick_time)[0][0]\n",
    "                    num_lick_right[trial_2p_index[right_lick_frame_ind]] += 1\n",
    "\n",
    "        if len(lick_times) > 0:\n",
    "            first_lick_time = np.amin(lick_times)\n",
    "            if first_lick_time < trial_2p_time[-1]:\n",
    "                first_lick_ind = np.where(trial_2p_time > first_lick_time)[0][0]\n",
    "                first_lick_frame[trial_2p_index[first_lick_ind]] = 1\n",
    "                if first_lick_time in left_lick_times:\n",
    "                    first_lick_left[trial_2p_index[first_lick_ind]] = 1\n",
    "                elif first_lick_time in right_lick_times:\n",
    "                    first_lick_right[trial_2p_index[first_lick_ind]] = 1\n",
    "                else:\n",
    "                    raise('First lick should be in either left or right beam break times')\n",
    "        \n",
    "        answer_lick_time = trial_behavior_series.answerLickTime\n",
    "        if answer_lick_time != 0: # answer trial\n",
    "            answer_lick_frame_ind = np.where(trial_2p_time > answer_lick_time)[0][0]\n",
    "            answer_lick_frame[trial_2p_index[answer_lick_frame_ind]] == 1\n",
    "            if answer_lick_time in left_lick_times:\n",
    "                answer_lick_left[trial_2p_index[answer_lick_frame_ind]] = 1\n",
    "            elif answer_lick_time in right_lick_times:\n",
    "                answer_lick_right[trial_2p_index[answer_lick_frame_ind]] = 1\n",
    "            else:\n",
    "                raise('Answer lick assignment should have been corrected.')\n",
    "            \n",
    "            if not np.array(trial_behavior_series.drinkingTime==[0,0]).all(): # correct trial\n",
    "                correct[trial_2p_index] = 1\n",
    "                if answer_lick_time in left_lick_times: # left trial\n",
    "                    if left_lick_times[-1] > answer_lick_time: # else, the reward was not taken during the trial\n",
    "                        first_reward_lick_time = left_lick_times[np.where(left_lick_times > answer_lick_time)[0][0]]\n",
    "                        if trial_2p_time[-1] > first_reward_lick_time: # else, the reward was not taken during 2p imaging for the trial\n",
    "                            first_reward_lick_frame_ind = np.where(trial_2p_time > first_reward_lick_time)[0][0]\n",
    "                            first_reward_lick_frame[trial_2p_index[first_reward_lick_frame_ind]] = 1\n",
    "                            first_reward_lick_left[trial_2p_index[first_reward_lick_frame_ind]] = 1\n",
    "                else: # right trial. Exception error dealt above\n",
    "                    if right_lick_times[-1] > answer_lick_time: # else, the reward was not taken during the trial\n",
    "                        first_reward_lick_time = right_lick_times[np.where(right_lick_times > answer_lick_time)[0][0]]\n",
    "                        if trial_2p_time[-1] > first_reward_lick_time: # else, the reward was not taken during 2p imaging for the trial\n",
    "                            first_reward_lick_frame_ind = np.where(trial_2p_time > first_reward_lick_time)[0][0]\n",
    "                            first_reward_lick_frame[trial_2p_index[first_reward_lick_frame_ind]] = 1\n",
    "                            first_reward_lick_right[trial_2p_index[first_reward_lick_frame_ind]] = 1\n",
    "            else:\n",
    "                wrong[trial_2p_index] = 1\n",
    "            \n",
    "            trial_pole_up_frame = frame_time_df.pole_up_frame.values[trial_2p_index]\n",
    "            trial_pre_answer_frame = np.zeros(len(trial_pole_up_frame), dtype=bool)\n",
    "            trial_pre_answer_frame[:answer_lick_frame_ind] = 1\n",
    "            pre_answer_pole_up_frame[trial_2p_index] = trial_pole_up_frame * trial_pre_answer_frame\n",
    "            trial_post_answer_frame = np.zeros(len(trial_pole_up_frame), dtype=bool)\n",
    "            trial_post_answer_frame[answer_lick_frame_ind+1:] = 1\n",
    "            post_answer_pole_up_frame[trial_2p_index] = trial_pole_up_frame * trial_post_answer_frame\n",
    "            \n",
    "        else:\n",
    "            miss[trial_2p_index] = 1\n",
    "\n",
    "        answer_period_time = trial_behavior_series.answerPeriodTime\n",
    "        answer_period_frame_first_ind = np.where(trial_2p_time > answer_period_time[0])[0][0]\n",
    "        answer_period_frame_last_ind = np.where(trial_2p_time > answer_period_time[1])[0][0]\n",
    "        answer_period_frame[trial_2p_index[answer_period_frame_first_ind:answer_period_frame_last_ind+1]] = 1\n",
    "\n",
    "    # Adding to the DataFrame\n",
    "    frame_time_df['pole_angle'] = pole_angle\n",
    "    frame_time_df['pole_ap_distance'] = pole_ap_distance\n",
    "    frame_time_df['pole_radial_distance'] = pole_radial_distance\n",
    "    frame_time_df['first_lick_frame'] = first_lick_frame\n",
    "    frame_time_df['first_lick_left'] = first_lick_left\n",
    "    frame_time_df['first_lick_right'] = first_lick_right\n",
    "    frame_time_df['num_lick_left'] = num_lick_left\n",
    "    frame_time_df['num_lick_right'] = num_lick_right\n",
    "    frame_time_df['answer_lick_frame'] = answer_lick_frame\n",
    "    frame_time_df['answer_lick_left'] = answer_lick_left\n",
    "    frame_time_df['answer_lick_right'] = answer_lick_right\n",
    "    frame_time_df['pre_answer_pole_up_frame'] = pre_answer_pole_up_frame\n",
    "    frame_time_df['answer_period_frame'] = answer_period_frame\n",
    "    frame_time_df['post_answer_pole_up_frame'] = post_answer_pole_up_frame\n",
    "    frame_time_df['first_reward_lick_frame'] = first_reward_lick_frame\n",
    "    frame_time_df['first_reward_lick_left'] = first_reward_lick_left\n",
    "    frame_time_df['first_reward_lick_right'] = first_reward_lick_right\n",
    "    frame_time_df['correct'] = correct\n",
    "    frame_time_df['wrong'] = wrong\n",
    "    frame_time_df['miss'] = miss\n",
    "    frame_time_df['trial_type'] = trial_type\n",
    "    frame_time_df['task_target'] = task_target\n",
    "    frame_time_df['distractor'] = distractor\n",
    "\n",
    "    # Additional information\n",
    "    frame_time_df['mouse_name'] = behavior_df.iloc[0].mouse_name\n",
    "    frame_time_df['session_name'] = behavior_df.iloc[0].session_name\n",
    "    frame_time_df['session_type'] = behavior_df.iloc[0].session_type\n",
    "\n",
    "    return frame_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing JK030 S01 plane #1\n",
      "Processing JK030 S02 plane #1\n",
      "Processing JK030 S03 plane #1\n",
      "Processing JK030 S05 plane #1\n",
      "Processing JK030 S12 plane #1\n",
      "Processing JK030 S18 plane #1\n",
      "Processing JK030 S19 plane #1\n",
      "Processing JK030 S20 plane #1\n",
      "Processing JK030 S21 plane #1\n",
      "Processing JK030 S22 plane #1\n",
      "Processing JK030 S901 plane #1\n",
      "Processing JK030 S902 plane #1\n",
      "Processing JK030 S01 plane #2\n",
      "Processing JK030 S02 plane #2\n",
      "Processing JK030 S03 plane #2\n",
      "Processing JK030 S05 plane #2\n",
      "Processing JK030 S12 plane #2\n",
      "Processing JK030 S18 plane #2\n",
      "Processing JK030 S19 plane #2\n",
      "Processing JK030 S20 plane #2\n",
      "Processing JK030 S21 plane #2\n",
      "Processing JK030 S22 plane #2\n",
      "Processing JK030 S901 plane #2\n",
      "Processing JK030 S902 plane #2\n",
      "Processing JK030 S01 plane #3\n",
      "Processing JK030 S02 plane #3\n",
      "Processing JK030 S03 plane #3\n",
      "Processing JK030 S05 plane #3\n",
      "Processing JK030 S12 plane #3\n",
      "Processing JK030 S18 plane #3\n",
      "Processing JK030 S19 plane #3\n",
      "Processing JK030 S20 plane #3\n",
      "Processing JK030 S21 plane #3\n",
      "Processing JK030 S22 plane #3\n",
      "Processing JK030 S901 plane #3\n",
      "Processing JK030 S902 plane #3\n",
      "Processing JK030 S01 plane #4\n",
      "Processing JK030 S02 plane #4\n",
      "Processing JK030 S03 plane #4\n",
      "Processing JK030 S05 plane #4\n",
      "Processing JK030 S12 plane #4\n",
      "Processing JK030 S18 plane #4\n",
      "Processing JK030 S19 plane #4\n",
      "Processing JK030 S20 plane #4\n",
      "Processing JK030 S21 plane #4\n",
      "Processing JK030 S22 plane #4\n",
      "Processing JK030 S901 plane #4\n",
      "Processing JK030 S902 plane #4\n",
      "Processing JK030 S01 plane #5\n",
      "Processing JK030 S02 plane #5\n",
      "Processing JK030 S03 plane #5\n",
      "Processing JK030 S05 plane #5\n",
      "Processing JK030 S06 plane #5\n",
      "Processing JK030 S07 plane #5\n",
      "Processing JK030 S09 plane #5\n",
      "Processing JK030 S11 plane #5\n",
      "Processing JK030 S12 plane #5\n",
      "Processing JK030 S14 plane #5\n",
      "Processing JK030 S15 plane #5\n",
      "Processing JK030 S17 plane #5\n",
      "Processing JK030 S18 plane #5\n",
      "Processing JK030 S19 plane #5\n",
      "Processing JK030 S20 plane #5\n",
      "Processing JK030 S21 plane #5\n",
      "Processing JK030 S22 plane #5\n",
      "Processing JK030 S901 plane #5\n",
      "Processing JK030 S902 plane #5\n",
      "Processing JK030 S01 plane #6\n",
      "Processing JK030 S02 plane #6\n",
      "Processing JK030 S03 plane #6\n",
      "Processing JK030 S05 plane #6\n",
      "Processing JK030 S06 plane #6\n",
      "Processing JK030 S07 plane #6\n",
      "Processing JK030 S09 plane #6\n",
      "Processing JK030 S11 plane #6\n",
      "Processing JK030 S12 plane #6\n",
      "Processing JK030 S14 plane #6\n",
      "Processing JK030 S15 plane #6\n",
      "Processing JK030 S17 plane #6\n",
      "Processing JK030 S18 plane #6\n",
      "Processing JK030 S19 plane #6\n",
      "Processing JK030 S20 plane #6\n",
      "Processing JK030 S21 plane #6\n",
      "Processing JK030 S22 plane #6\n",
      "Processing JK030 S901 plane #6\n",
      "Processing JK030 S902 plane #6\n",
      "Processing JK030 S01 plane #7\n",
      "Processing JK030 S02 plane #7\n",
      "Processing JK030 S03 plane #7\n",
      "Processing JK030 S05 plane #7\n",
      "Processing JK030 S06 plane #7\n",
      "Processing JK030 S07 plane #7\n",
      "Processing JK030 S09 plane #7\n",
      "Processing JK030 S11 plane #7\n",
      "Processing JK030 S12 plane #7\n",
      "Processing JK030 S14 plane #7\n",
      "Processing JK030 S15 plane #7\n",
      "Processing JK030 S17 plane #7\n",
      "Processing JK030 S18 plane #7\n",
      "Processing JK030 S19 plane #7\n",
      "Processing JK030 S20 plane #7\n",
      "Processing JK030 S21 plane #7\n",
      "Processing JK030 S22 plane #7\n",
      "Processing JK030 S901 plane #7\n",
      "Processing JK030 S902 plane #7\n",
      "Processing JK030 S01 plane #8\n",
      "Processing JK030 S02 plane #8\n",
      "Processing JK030 S03 plane #8\n",
      "Processing JK030 S05 plane #8\n",
      "Processing JK030 S06 plane #8\n",
      "Processing JK030 S07 plane #8\n",
      "Processing JK030 S09 plane #8\n",
      "Processing JK030 S11 plane #8\n",
      "Processing JK030 S12 plane #8\n",
      "Processing JK030 S14 plane #8\n",
      "Processing JK030 S15 plane #8\n",
      "Processing JK030 S17 plane #8\n",
      "Processing JK030 S18 plane #8\n",
      "Processing JK030 S19 plane #8\n",
      "Processing JK030 S20 plane #8\n",
      "Processing JK030 S21 plane #8\n",
      "Processing JK030 S22 plane #8\n",
      "Processing JK030 S901 plane #8\n",
      "Processing JK030 S902 plane #8\n"
     ]
    }
   ],
   "source": [
    "expert_mice_ind = [0,1,2,3,6,8]\n",
    "\n",
    "# for emi in range(3):\n",
    "for emi in [2]:\n",
    "    mi = expert_mice_ind[emi]\n",
    "    mouse = mice[mi]\n",
    "    # if emi < 3:\n",
    "    #     h5_dir = h5_dir_1\n",
    "    # else:\n",
    "    #     h5_dir = h5_dir_2\n",
    "\n",
    "    for plane in planes:\n",
    "        plane_dir = h5_dir / f'{mouse:03d}' / f'plane_{plane}'\n",
    "        sts_reg = np.load(plane_dir / f'JK{mouse:03d}_plane{plane}_session_to_session_registration.npy', allow_pickle=True).item()\n",
    "        session_nums = sts_reg['selected_session_num']\n",
    "        # This info is valid in pi:pi+4\n",
    "\n",
    "        for session_num in session_nums:\n",
    "            if session_num > 900:\n",
    "                wb_snum = session_num // 10 + session_num % 900 # pre1 is 901 in calcium but 91 in behavior and whisker\n",
    "            else:\n",
    "                wb_snum = session_num\n",
    "            # Load whisker\n",
    "            w_path = w_dir / f'JK{mouse:03d}S{wb_snum:02d}' / f'JK{mouse:03d}S{wb_snum:02d}_whisker.pkl'\n",
    "            if os.path.isfile(w_path):\n",
    "                whisker_df = pd.read_pickle(w_path)\n",
    "                # Load behavior\n",
    "                b_path = b_dir / f'JK{mouse:03d}' / f'JK{mouse:03d}S{wb_snum:02d}_behavior.pkl'\n",
    "                behavior_df = pd.read_pickle(b_path)\n",
    "                # Load frame times\n",
    "                tf_path = h5_dir / f'{mouse:03d}' / f'plane_{plane}' / f'{mouse:03d}_{session_num:03d}_plane_{plane}_frame_time.pkl'\n",
    "                frame_time_df = pd.read_pickle(tf_path)\n",
    "\n",
    "                print(f'Processing JK{mouse:03d} S{session_num:02d} plane #{plane}')\n",
    "\n",
    "                frame_time_df = merge_whisker_to_frame_df(frame_time_df, whisker_df)\n",
    "                frame_time_df = merge_behavior_to_frame_df(frame_time_df, behavior_df)\n",
    "\n",
    "                # save\n",
    "                save_fn = f'JK{mouse:03d}_S{session_num:02d}_plane{plane}_frame_whisker_behavior.pkl'\n",
    "                frame_time_df.to_pickle(plane_dir/save_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_mice_ind = [0,1,2,3,6,8]\n",
    "\n",
    "# for emi in range(3):\n",
    "for emi in [2]:\n",
    "    mi = expert_mice_ind[emi]\n",
    "    mouse = mice[mi]\n",
    "    # if emi < 3:\n",
    "    #     h5_dir = h5_dir_1\n",
    "    # else:\n",
    "    #     h5_dir = h5_dir_2\n",
    "\n",
    "    # for plane in planes:\n",
    "    for plane in [5,6,7,8]:\n",
    "        plane_dir = h5_dir / f'{mouse:03d}' / f'plane_{plane}'\n",
    "        sts_reg = np.load(plane_dir / f'JK{mouse:03d}_plane{plane}_session_to_session_registration.npy', allow_pickle=True).item()\n",
    "        # session_nums = sts_reg['selected_session_num']\n",
    "        # This info is valid in pi:pi+4\n",
    "\n",
    "        # for session_num in session_nums:\n",
    "        for session_num in [8]:\n",
    "            if session_num > 900:\n",
    "                wb_snum = session_num // 10 + session_num % 900 # pre1 is 901 in calcium but 91 in behavior and whisker\n",
    "            else:\n",
    "                wb_snum = session_num\n",
    "            # Load whisker\n",
    "            w_path = w_dir / f'JK{mouse:03d}S{wb_snum:02d}' / f'JK{mouse:03d}S{wb_snum:02d}_whisker.pkl'\n",
    "            if os.path.isfile(w_path):\n",
    "                whisker_df = pd.read_pickle(w_path)\n",
    "                # Load behavior\n",
    "                b_path = b_dir / f'JK{mouse:03d}' / f'JK{mouse:03d}S{wb_snum:02d}_behavior.pkl'\n",
    "                behavior_df = pd.read_pickle(b_path)\n",
    "                # Load frame times\n",
    "                tf_path = h5_dir / f'{mouse:03d}' / f'plane_{plane}' / f'{mouse:03d}_{session_num:03d}_plane_{plane}_frame_time.pkl'\n",
    "                frame_time_df = pd.read_pickle(tf_path)\n",
    "\n",
    "                print(f'Processing JK{mouse:03d} S{session_num:02d} plane #{plane}')\n",
    "\n",
    "                frame_time_df = merge_whisker_to_frame_df(frame_time_df, whisker_df)\n",
    "                frame_time_df = merge_behavior_to_frame_df(frame_time_df, behavior_df)\n",
    "\n",
    "                # save\n",
    "                save_fn = f'JK{mouse:03d}_S{session_num:02d}_plane{plane}_frame_whisker_behavior.pkl'\n",
    "                frame_time_df.to_pickle(plane_dir/save_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(w_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('suite2p')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53092f88beb6d9efd0118112bc0e9c1c54eac338b7f8334bd9c460f5dc451b11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
