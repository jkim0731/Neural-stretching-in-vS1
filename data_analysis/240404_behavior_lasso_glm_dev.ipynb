{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose:\n",
    "- Develop lasso GLM for behavior data (whisker feature and angle)\n",
    "- using sklearn or pyglmnet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shires\\Anaconda3\\envs\\suite2p\\lib\\site-packages\\pandas\\core\\indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "from pyglmnet import GLM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('default')\n",
    "import xarray as xr\n",
    "from utils import lda_angle_discrim as lad\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "base_dir = Path(r'E:\\TPM\\JK\\h5')\n",
    "results_dir = base_dir / 'results'\n",
    "wf_dir = results_dir / 'touch_whisker_features'\n",
    "b_dir = Path(r'E:\\TPM\\JK\\SoloData')\n",
    "\n",
    "expert_mice_df = pd.read_csv(base_dir / 'expert_mice.csv', index_col=0)\n",
    "use_mice_df = expert_mice_df.loc[expert_mice_df['depth_matched'].astype(bool) & \n",
    "                                 ~expert_mice_df['processing_error'].astype(bool) &\n",
    "                                 ((expert_mice_df.session_type == 'training') |\n",
    "                                  (expert_mice_df.session_type.str.contains('test')))]\n",
    "use_volume_df = use_mice_df.query('plane in [1, 5]')\n",
    "use_volume_df.loc[:, 'volume'] = use_volume_df['plane'].apply(lambda x: 1 if x==1 else 2)\n",
    "training_volume_df = use_volume_df.query('session_type == \"training\"')\n",
    "remove_ind = training_volume_df.query('mouse==27 and session==\"15\"')\n",
    "training_volume_df = training_volume_df.drop(remove_ind.index)\n",
    "remove_ind = training_volume_df.query('mouse==36 and session==\"9\"')\n",
    "training_volume_df = training_volume_df.drop(remove_ind.index)\n",
    "\n",
    "mice = [25,27,30,36,39,52]\n",
    "test_sessions = [[4,19], [3,8], [3,21], [1,17], [1,23], [3,21]]\n",
    "naive_sessions = [10, 4, 11, 6, 6, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_for_whisker_feature_angle_discrim(wf_dir, b_dir, mouse, session,\n",
    "                                              touch_window='before_answer'):\n",
    "    whisker_feature_names = ['theta_onset', 'phi_onset', 'kappaH_onset', 'kappaV_onset',\n",
    "    'arcLength_onset', 'touch_count', 'delta_theta', 'delta_phi',\n",
    "    'delta_kappaH', 'delta_kappaV', 'touch_duration', 'slide_distance']\n",
    "\n",
    "    wf_fn = wf_dir / f'JK{mouse:03}S{session:02}_touch_whisker_features.pkl'\n",
    "    b_fn = b_dir / f'JK{mouse:03}/JK{mouse:03}S{session:02}_behavior.pkl'\n",
    "    \n",
    "    wf_df = pd.read_pickle(wf_fn)\n",
    "    b_df = pd.read_pickle(b_fn)\n",
    "    \n",
    "    if touch_window == 'before_answer':\n",
    "        wf_df = wf_df.groupby('trialNum').apply(\n",
    "            lambda x: x.query('touch_offset_time < answer_lick_time')).reset_index(\n",
    "                drop=True)\n",
    "    elif touch_window == 'after_answer':\n",
    "        wf_df = wf_df.groupby('trialNum').apply(\n",
    "            lambda x: x.query('pole_onset_time >= answer_lick_time')).reset_index(\n",
    "                drop=True)\n",
    "    elif touch_window == 'all':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Invalid touch_window')\n",
    "    \n",
    "    wf_mean = wf_df.groupby('trialNum').mean()\n",
    "    wf_mean['touch_count'] = wf_df.groupby('trialNum').size()\n",
    "    \n",
    "    b_df['outcome'] = b_df.apply(lambda x: _get_outcome(x), axis=1)\n",
    "    b_df['pole_angle'] = b_df['servoAngle']\n",
    "    \n",
    "    wf_mean = wf_mean.merge(b_df[['outcome','pole_angle']], on='trialNum')\n",
    "    # remove rows with NaN values\n",
    "    wf_mean = wf_mean.dropna()\n",
    "    \n",
    "    values = wf_mean.loc[:,whisker_feature_names].values\n",
    "    values = (values - values.mean(axis=0)) / values.std(axis=0)\n",
    "\n",
    "    X = xr.DataArray(values,\n",
    "                    dims=['trialNum', 'whisker_feature'],\n",
    "                    coords={'trialNum': wf_mean.index.values,\n",
    "                            'whisker_feature': whisker_feature_names})\n",
    "    y_temp = wf_mean['pole_angle'].values\n",
    "    angles = np.sort(np.unique(y_temp))\n",
    "    y = np.array([np.where(angles==a)[0][0] for a in y_temp])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def _get_outcome(x):\n",
    "    if x.choice == 'm':\n",
    "        return 'miss'\n",
    "    elif x.choice == 'l':\n",
    "        return 'correct' if x.trialType[0] == 'l' else 'wrong'\n",
    "    elif x.choice == 'r':\n",
    "        return 'correct' if x.trialType[0] == 'r' else 'wrong'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = 0\n",
    "mouse = mice[mi]\n",
    "sessions = np.sort([int(s) for s in use_mice_df.query('mouse==@mouse and session_type==\"training\"')['session'].unique()])\n",
    "si = 0\n",
    "session = sessions[si]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 4\n",
    "lam_list = np.logspace(-2, 0, 10)\n",
    "num_split_lam = 4\n",
    "X, y = get_x_y_for_whisker_feature_angle_discrim(wf_dir, b_dir, mouse, session, 'before_answer')\n",
    "splits_inds = lad.stratify_random_split(np.arange(len(y)), y, num_splits=num_splits)\n",
    "split_accuracies = []\n",
    "best_lam_list = []\n",
    "coeffs = []\n",
    "intercepts = []\n",
    "for si in range(num_splits):\n",
    "    train_inds = np.concatenate([splits_inds[i] for i in range(num_splits) if i != si])    \n",
    "    test_inds = splits_inds[si]\n",
    "    X_train = X[train_inds,:]\n",
    "    y_train = y[train_inds]\n",
    "    X_test = X[test_inds,:]\n",
    "    y_test = y[test_inds]\n",
    "\n",
    "    lam_splits_inds = lad.stratify_random_split(np.arange(len(y_train)), y_train,\n",
    "                                            num_splits=num_split_lam)\n",
    "    split_best_lam_list = []\n",
    "    for lsi in range(num_split_lam):\n",
    "        lam_train_inds = np.concatenate([lam_splits_inds[i] for i in range(num_split_lam) if i != lsi])\n",
    "        X_train_lam = X_train[lam_train_inds,:]\n",
    "        y_train_lam = y_train[lam_train_inds]\n",
    "        X_test_lam = X_train[lam_splits_inds[lsi],:]\n",
    "        y_test_lam = y_train[lam_splits_inds[lsi]]\n",
    "\n",
    "        lam_accuracies = []\n",
    "        for lam in lam_list:\n",
    "            clf = LogisticRegression(penalty='l1', solver='liblinear', C=lam)\n",
    "            clf.fit(X_train_lam, y_train_lam)\n",
    "            y_pred = clf.predict(X_test_lam)\n",
    "            lam_accuracies.append((y_pred == y_test_lam).mean())\n",
    "        lam_accuracies = np.array(lam_accuracies)\n",
    "        max_ind = np.argmax(lam_accuracies)\n",
    "        best_lam = lam_list[max_ind]\n",
    "        split_best_lam_list.append(best_lam)\n",
    "    best_lam = np.mean(split_best_lam_list)\n",
    "    best_lam_list.append(best_lam)\n",
    "    clf = LogisticRegression(penalty='l1', solver='liblinear', C=best_lam)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    split_accuracies.append((y_pred == y_test).mean())\n",
    "    coeffs.append(clf.coef_)\n",
    "    intercepts.append(clf.intercept_)\n",
    "mean_coeffs = np.mean(np.array(coeffs), axis=0)\n",
    "mean_intercept = np.mean(np.array(intercepts), axis=0)\n",
    "mean_accuracy = np.mean(split_accuracies)\n",
    "classes = clf.classes_\n",
    "clf = LogisticRegression(penalty='l1', solver='liblinear', C=np.mean(best_lam_list))\n",
    "clf.classes_ = classes\n",
    "clf.coef_ = mean_coeffs\n",
    "clf.intercept_ = mean_intercept\n",
    "y_pred = clf.predict(X)\n",
    "final_accuracy = (y_pred == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "feature_importance = []\n",
    "for feature in X.whisker_feature.values:\n",
    "    X_temp = X.copy()\n",
    "    X_temp.loc[:,feature] = 0\n",
    "    y_pred_temp = clf.predict(X_temp)\n",
    "    accuracy_temp = (y_pred_temp == y).mean()\n",
    "    feature_importance.append((final_accuracy - accuracy_temp) / final_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = xr.DataArray(feature_importance, dims=['whisker_feature'], coords={'whisker_feature': X.whisker_feature.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lasso_logistic_results(mouse, session, wf_dir, b_dir,\n",
    "                               num_splits=4, num_split_lam=4,\n",
    "                               lam_list=np.logspace(-2, 0, 10)):\n",
    "    X, y = get_x_y_for_whisker_feature_angle_discrim(wf_dir, b_dir, mouse, session, 'before_answer')\n",
    "    splits_inds = lad.stratify_random_split(np.arange(len(y)), y, num_splits=num_splits)\n",
    "    split_accuracies = []\n",
    "    best_lam_list = []\n",
    "    coeffs = []\n",
    "    intercepts = []\n",
    "    lam_split_inds_list = []\n",
    "    for si in range(num_splits):\n",
    "        train_inds = np.concatenate([splits_inds[i] for i in range(num_splits) if i != si])    \n",
    "        test_inds = splits_inds[si]\n",
    "        X_train = X[train_inds,:]\n",
    "        y_train = y[train_inds]\n",
    "        X_test = X[test_inds,:]\n",
    "        y_test = y[test_inds]\n",
    "\n",
    "        lam_splits_inds = lad.stratify_random_split(np.arange(len(y_train)), y_train,\n",
    "                                                num_splits=num_split_lam)\n",
    "        lam_split_inds_list.append(lam_splits_inds)\n",
    "        split_best_lam_list = []\n",
    "        for lsi in range(num_split_lam):\n",
    "            lam_train_inds = np.concatenate([lam_splits_inds[i] for i in range(num_split_lam) if i != lsi])\n",
    "            X_train_lam = X_train[lam_train_inds,:]\n",
    "            y_train_lam = y_train[lam_train_inds]\n",
    "            X_test_lam = X_train[lam_splits_inds[lsi],:]\n",
    "            y_test_lam = y_train[lam_splits_inds[lsi]]\n",
    "\n",
    "            lam_accuracies = []\n",
    "            for lam in lam_list:\n",
    "                clf = LogisticRegression(penalty='l1', solver='liblinear', C=lam)\n",
    "                clf.fit(X_train_lam, y_train_lam)\n",
    "                y_pred = clf.predict(X_test_lam)\n",
    "                lam_accuracies.append((y_pred == y_test_lam).mean())\n",
    "            lam_accuracies = np.array(lam_accuracies)\n",
    "            max_ind = np.argmax(lam_accuracies)\n",
    "            best_lam = lam_list[max_ind]\n",
    "            split_best_lam_list.append(best_lam)\n",
    "        best_lam = np.mean(split_best_lam_list)\n",
    "        best_lam_list.append(best_lam)\n",
    "        clf = LogisticRegression(penalty='l1', solver='liblinear', C=best_lam)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        split_accuracies.append((y_pred == y_test).mean())\n",
    "        coeffs.append(clf.coef_)\n",
    "        intercepts.append(clf.intercept_)\n",
    "    mean_coeffs = np.mean(np.array(coeffs), axis=0)\n",
    "    mean_intercept = np.mean(np.array(intercepts), axis=0)\n",
    "    mean_accuracy = np.mean(split_accuracies)\n",
    "    classes = clf.classes_\n",
    "    clf = LogisticRegression(penalty='l1', solver='liblinear', C=np.mean(best_lam_list))\n",
    "    clf.classes_ = classes\n",
    "    clf.coef_ = mean_coeffs\n",
    "    clf.intercept_ = mean_intercept\n",
    "    y_pred = clf.predict(X)\n",
    "    final_accuracy = (y_pred == y).mean()\n",
    "\n",
    "    # feature importance\n",
    "    feature_importance = []\n",
    "    for feature in X.whisker_feature.values:\n",
    "        X_temp = X.copy()\n",
    "        X_temp.loc[:,feature] = 0\n",
    "        y_pred_temp = clf.predict(X_temp)\n",
    "        accuracy_temp = (y_pred_temp == y).mean()\n",
    "        feature_importance.append((final_accuracy - accuracy_temp) / final_accuracy)\n",
    "    feature_importance = xr.DataArray(feature_importance,\n",
    "                                      dims=['whisker_feature'],\n",
    "                                      coords={'whisker_feature': X.whisker_feature.values})\n",
    "\n",
    "    return final_accuracy, feature_importance, classes, mean_coeffs, mean_intercept, mean_accuracy, best_lam_list, splits_inds, lam_split_inds_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_accuracy, feature_importance, classes, mean_coeffs, mean_intercept, mean_accuracy, best_lam_list, splits_inds, lam_split_inds_list = \\\n",
    "    get_lasso_logistic_results(mouse, session, wf_dir, b_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suite2p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
