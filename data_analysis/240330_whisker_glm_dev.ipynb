{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose:\n",
    "- Develop \"whisker GLM\"\n",
    "- Similar to \"touch GLM\" (240131_glm_test.ipynb)\n",
    "- whisker feature values outside of touch frames were set to 0, AFTER standardization.\n",
    "    - This works because the model is about \"variation\" in neuronal activity upon touch, and whisker features are going to be standardized.\n",
    "    - Outside of touch frames will have no effect from the coefficients of whisker features, and bias will take care of negative-positive response distribution upon whisker features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_dir = Path(r'E:\\TPM\\JK\\h5')\n",
    "results_dir = Path(r'E:\\TPM\\JK\\results')\n",
    "\n",
    "expert_mice_df = pd.read_csv(base_dir / 'expert_mice.csv', index_col=0)\n",
    "use_mice_df = expert_mice_df.loc[expert_mice_df['depth_matched'].astype(bool) & \n",
    "                                 ~expert_mice_df['processing_error'].astype(bool) &\n",
    "                                 ((expert_mice_df.session_type == 'training') |\n",
    "                                  (expert_mice_df.session_type.str.contains('test')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_with_nan_values(data):\n",
    "    mean = np.nanmean(data)\n",
    "    std = np.nanstd(data)\n",
    "    standardized_data = (data - mean) / std\n",
    "    nan_inds = np.where(np.isnan(standardized_data))[0]\n",
    "    standardized_data[nan_inds] = np.nanmean(standardized_data)\n",
    "    return standardized_data\n",
    "\n",
    "\n",
    "def make_design_dataframe(mouse, plane, session, base_dir,\n",
    "                          whisker_feature_offsets=np.arange(0,3),\n",
    "                          whisking_offsets=np.arange(-2,5),\n",
    "                          lick_offsets=np.arange(-2,3),\n",
    "                          sound_offsets=np.arange(0,5),\n",
    "                          reward_offsets=np.arange(0,5)):\n",
    "    plane_dir = base_dir / f'{mouse:03}/plane_{plane}'\n",
    "    behavior_fn = plane_dir / f'JK{mouse:03}_S{session:02}_plane{plane}_frame_whisker_behavior.pkl'\n",
    "    if not behavior_fn.exists():\n",
    "        raise FileNotFoundError(f'{behavior_fn} does not exist')\n",
    "    behavior_frametime = pd.read_pickle(plane_dir / f'JK{mouse:03}_S{session:02}_plane{plane}_frame_whisker_behavior.pkl')\n",
    "    roi_dir = plane_dir / f'{session:03}/plane0/roi'\n",
    "    ophys_fn = roi_dir / 'refined_frame_time.pkl'\n",
    "    if not ophys_fn.exists():\n",
    "        raise FileNotFoundError(f'{ophys_fn} does not exist')\n",
    "    ophys_frametime = pd.read_pickle(roi_dir / 'refined_frame_time.pkl')\n",
    "\n",
    "    # remove those with remove_trial==True (from expert_mice.csv)\n",
    "    refined_ophys_frametime = ophys_frametime.query('remove_trial==False')\n",
    "    assert refined_ophys_frametime.remove_frame.values.sum() == 0\n",
    "    # extend each trial frames by 1 in each direction (those trimmed to make reduced_frame_time.pkl from frame_time.pkl)\n",
    "    # so that I can have 2 more frame of information (from behavior_frametime)\n",
    "    extended_ophys_df = refined_ophys_frametime.groupby('trialNum').apply(extend_dataframe).reset_index(drop=True)\n",
    "\n",
    "    # merge with behavior_frametime\n",
    "    reduced_behavior_columns = np.setdiff1d(behavior_frametime.columns,\n",
    "                                            np.setdiff1d(extended_ophys_df.columns,\n",
    "                                                         ['trialNum', 'frame_index']))\n",
    "    reduced_behavior_df = behavior_frametime[reduced_behavior_columns]\n",
    "    merged_df = pd.merge(extended_ophys_df, reduced_behavior_df,\n",
    "                         on=['trialNum', 'frame_index'], how='inner')\n",
    "\n",
    "    # remove catch trials\n",
    "    catch_trial_nums = merged_df.query('trial_type == \"oo\"')['trialNum'].unique()\n",
    "    merged_df = merged_df.query('trialNum not in @catch_trial_nums').reset_index().copy()\n",
    "    assert 'oo' not in merged_df['trial_type'].unique()\n",
    "    \n",
    "    # Assign pole in sound and pole out sound cue frames\n",
    "    assert not merged_df.groupby('trialNum').apply(lambda x: len(np.where(x['pole_up_frame']==1)[0])==0).any()\n",
    "    merged_df['pole_in_frame'] = merged_df.groupby('trialNum').apply(lambda x: x['frame_index'] == x['frame_index'].values[np.where(x['pole_up_frame']==True)[0][0]-1]).reset_index(drop=True).values    \n",
    "    merged_df['pole_out_frame'] = merged_df.groupby('trialNum').apply(apply_pole_out).reset_index(drop=True).values\n",
    "\n",
    "    # Initialize names\n",
    "    whisker_feature_names = ['theta_onset', 'phi_onset', 'kappaH_onset', 'kappaV_onset',\n",
    "                            'arc_length_onset', 'touch_count', 'delta_theta', 'delta_phi',\n",
    "                            'delta_kappaH', 'delta_kappaV', 'touch_duration', 'slide_distance']\n",
    "    lick_names = ['num_lick_left', 'num_lick_right']\n",
    "    whisking_names = ['num_whisks', 'midpoint', 'amplitude']\n",
    "    reward_names = ['first_reward_lick_left', 'first_reward_lick_right']\n",
    "    sound_names = ['pole_in_frame', 'pole_out_frame']\n",
    "\n",
    "    # Standardize and apply mean after standardization for whisker features\n",
    "    # except for touch count (replace nan to 0 for touch count)\n",
    "    for whisker_feature_name in whisker_feature_names:\n",
    "        if whisker_feature_name != 'touch_count':\n",
    "            merged_df.loc[:,whisker_feature_name] = standardize_with_nan_values(merged_df.loc[:,whisker_feature_name].values)\n",
    "    merged_df[f'touch_count'] = merged_df[f'touch_count'].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "\n",
    "    # Build design dataframe\n",
    "    design_df = merged_df[['trialNum','frame_index']].copy()\n",
    "    for whisker_feature_name in whisker_feature_names:\n",
    "        for offset in whisker_feature_offsets:\n",
    "            values_to_assign = merged_df.groupby('trialNum').apply(lambda x: x[whisker_feature_name].shift(offset)).reset_index(drop=True).values\n",
    "            design_df.loc[:,f'{whisker_feature_name}_{offset}'] = values_to_assign\n",
    "    for whisking_name in whisking_names:\n",
    "        for offset in whisking_offsets:\n",
    "            design_df[f'{whisking_name}_{offset}'] = merged_df.groupby('trialNum').apply(lambda x: x[whisking_name].shift(offset)).reset_index(drop=True).values\n",
    "    for lick_name in lick_names:\n",
    "        for offset in lick_offsets:\n",
    "            design_df[f'{lick_name}_{offset}'] = merged_df.groupby('trialNum').apply(lambda x: x[lick_name].shift(offset)).reset_index(drop=True).values\n",
    "    for sound_name in sound_names:\n",
    "        for offset in sound_offsets:\n",
    "            design_df[f'{sound_name}_{offset}'] = merged_df.groupby('trialNum').apply(lambda x: x[sound_name].shift(offset)).reset_index(drop=True).values\n",
    "    for reward_name in reward_names:\n",
    "        for offset in reward_offsets:\n",
    "            design_df[f'{reward_name}_{offset}'] = merged_df.groupby('trialNum').apply(lambda x: x[reward_name].shift(offset)).reset_index(drop=True).values\n",
    "\n",
    "    return design_df, merged_df\n",
    "\n",
    "\n",
    "def extend_dataframe(group, n_before=1, n_after=1):\n",
    "    before_rows = group.iloc[0:n_before].copy().reset_index(drop=True)\n",
    "    before_rows[:] = np.nan\n",
    "    before_rows.trialNum = group.trialNum.iloc[0]\n",
    "    before_rows.frame_index = -1\n",
    "    before_rows.loc[before_rows.index.max(), 'frame_index'] = group.frame_index.min()-1\n",
    "    after_rows = group.iloc[-n_after:].copy().reset_index(drop=True)\n",
    "    after_rows[:] = np.nan\n",
    "    after_rows.trialNum = group.trialNum.iloc[-1]\n",
    "    after_rows.frame_index = -1\n",
    "    after_rows.loc[0,'frame_index'] = group.frame_index.max()+1\n",
    "    extended_group = pd.concat([before_rows, group, after_rows], ignore_index=True)\n",
    "    return extended_group\n",
    "\n",
    "\n",
    "def apply_pole_out(x):\n",
    "     if np.where(x['pole_up_frame']==True)[0][-1] < len(x)-1:\n",
    "          return x['frame_index'] == x['frame_index'].values[np.where(x['pole_up_frame']==True)[0][-1]]\n",
    "     else:\n",
    "          return pd.Series([False]*len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design matrix dev for whisker GLM\n",
    "- Use touch whisker features \n",
    "    - Calculated and saved by ..\\data_processing\\240328_build_whisker_feature_dataframe_dev.ipynb\n",
    "- Other features the same as from touch GLM, except for pole angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = 25\n",
    "plane = 1\n",
    "session = 3\n",
    "plane_dir = base_dir / f'{mouse:03}/plane_{plane}'\n",
    "behavior_frametime = pd.read_pickle(plane_dir / f'JK{mouse:03}_S{session:02}_plane{plane}_frame_whisker_behavior.pkl')\n",
    "roi_dir = plane_dir / f'{session:03}/plane0/roi'\n",
    "ophys_frametime = pd.read_pickle(roi_dir / 'refined_frame_time.pkl')\n",
    "refined_ophys_frametime = ophys_frametime.query('remove_trial==False').reset_index()\n",
    "assert refined_ophys_frametime.remove_frame.values.sum() == 0\n",
    "extended_ophys_df = refined_ophys_frametime.groupby('trialNum').apply(extend_dataframe).reset_index(drop=True)\n",
    "reduced_behavior_columns = np.setdiff1d(behavior_frametime.columns,np.setdiff1d(extended_ophys_df.columns, ['trialNum', 'frame_index']))\n",
    "reduced_behavior_df = behavior_frametime[reduced_behavior_columns]\n",
    "merged_df = pd.merge(extended_ophys_df, reduced_behavior_df, on=['trialNum', 'frame_index'], how='outer')\n",
    "    # Here outer join is to keep behavior data preceeding and following ophys frames\n",
    "constant_columns = ['correct', 'wrong', 'miss', 'trial_type', 'task_target', 'distractor', 'mouse_name', 'session_name', 'session_type', 'trial_duration']\n",
    "# Assigne pole_moving_up and pole_moving_down to the frames\n",
    "# First check if all trials have correct pole up pole moving frames\n",
    "# Sometimes there is no pole_moving_frame\n",
    "# Just use -1 of the first pole up and the last of pole up frame as pole_in_frame and pole_out_frame\n",
    "assert not merged_df.groupby('trialNum').apply(lambda x: len(np.where(x['pole_up_frame']==1)[0])==0).any()\n",
    "merged_df['pole_in_frame'] = merged_df.groupby('trialNum').apply(lambda x: x['frame_index'] == x['frame_index'].values[np.where(x['pole_up_frame']==True)[0][0]-1]).reset_index(drop=True).values\n",
    "merged_df['pole_out_frame'] = merged_df.groupby('trialNum').apply(lambda x: x['frame_index'] == x['frame_index'].values[np.where(x['pole_up_frame']==True)[0][-1]]).reset_index(drop=True).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisker_feature_names = ['theta_onset', 'phi_onset', 'kappaH_onset', 'kappaV_onset',\n",
    "'arc_length_onset', 'touch_count', 'delta_theta', 'delta_phi',\n",
    "'delta_kappaH', 'delta_kappaV', 'touch_duration', 'slide_distance']\n",
    "lick_names = ['num_lick_left', 'num_lick_right']\n",
    "whisking_names = ['num_whisks', 'midpoint', 'amplitude']\n",
    "reward_names = ['first_reward_lick_left', 'first_reward_lick_right']\n",
    "sound_names = ['pole_in_frame', 'pole_out_frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.774826430871863"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = merged_df.theta_onset.values\n",
    "np.nanmean(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.809203189576923"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanstd(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_std = (theta - np.nanmean(theta)) / np.nanstd(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_inds = np.where(np.isnan(theta_std))[0]\n",
    "theta_std[nan_inds] = np.nanmean(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for whisker_feature_name in whisker_feature_names:\n",
    "    if whisker_feature_name != 'touch_count':\n",
    "        merged_df.loc[:,whisker_feature_name] = standardize_with_nan_values(merged_df.loc[:,whisker_feature_name].values)\n",
    "\n",
    "merged_df[f'touch_count'] = merged_df[f'touch_count'].apply(lambda x: 0 if np.isnan(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisker_feature_offsets = np.arange(0,3)\n",
    "whisking_offsets = np.arange(-2,5)\n",
    "lick_offsets = np.arange(-2,3)\n",
    "sound_offsets = np.arange(0,5)\n",
    "reward_offsets = np.arange(0,5)\n",
    "\n",
    "design_df = merged_df[['trialNum','frame_index']].copy()\n",
    "for whisker_feature_name in whisker_feature_names:\n",
    "    for offset in whisker_feature_offsets:\n",
    "        values_to_assign = merged_df.groupby('trialNum').apply(lambda x: x[whisker_feature_name].shift(offset)).reset_index(drop=True).values\n",
    "        assert len(values_to_assign) == len(design_df)\n",
    "        design_df.loc[:,f'{whisker_feature_name}_{offset}'] = values_to_assign\n",
    "for whisking_name in whisking_names:\n",
    "    for offset in whisking_offsets:\n",
    "        values_to_assign = merged_df.groupby('trialNum').apply(lambda x: x[whisking_name].shift(offset)).reset_index(drop=True).values\n",
    "        assert len(values_to_assign) == len(design_df)\n",
    "        design_df.loc[:,f'{whisking_name}_{offset}'] = values_to_assign\n",
    "for lick_name in lick_names:\n",
    "    for offset in lick_offsets:\n",
    "        values_to_assign = merged_df.groupby('trialNum').apply(lambda x: x[lick_name].shift(offset)).reset_index(drop=True).values\n",
    "        assert len(values_to_assign) == len(design_df)\n",
    "        design_df.loc[:,f'{lick_name}_{offset}'] = values_to_assign\n",
    "for sound_name in sound_names:\n",
    "    for offset in sound_offsets:\n",
    "        values_to_assign = merged_df.groupby('trialNum').apply(lambda x: x[sound_name].shift(offset)).reset_index(drop=True).values\n",
    "        assert len(values_to_assign) == len(design_df)\n",
    "        design_df.loc[:,f'{sound_name}_{offset}'] = values_to_assign\n",
    "for reward_name in reward_names:\n",
    "    for offset in reward_offsets:\n",
    "        values_to_assign = merged_df.groupby('trialNum').apply(lambda x: x[reward_name].shift(offset)).reset_index(drop=True).values\n",
    "        assert len(values_to_assign) == len(design_df)\n",
    "        design_df.loc[:,f'{reward_name}_{offset}'] = values_to_assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# for i, row in tqdm(use_mice_df.iterrows()):\n",
    "#     mouse = row['mouse']\n",
    "#     plane = row['plane']\n",
    "#     session = int(row['session'])\n",
    "#     design_df, _ = make_design_dataframe(mouse, plane, session, base_dir)\n",
    "#     save_dir = base_dir / f'{mouse:03}/plane_{plane}/{session:03}/plane0/roi/glm/whisker_combined'\n",
    "#     save_dir.mkdir(exist_ok=True, parents=True)\n",
    "#     design_df.to_pickle(save_dir / 'whisker_combined_design.pkl')\n",
    "\n",
    "# Run this using scripts\\design_matrix_whisker_combined_par.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whisker combined GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = 25\n",
    "plane = 1\n",
    "session = 1\n",
    "\n",
    "standardize_features=True\n",
    "standardize_traces=True\n",
    "\n",
    "roi_dir = base_dir / f'{mouse:03}/plane_{plane}/{session:03}/plane0/roi'\n",
    "glm_dir = roi_dir / f'glm/whisker_combined'\n",
    "design_df = pd.read_pickle(glm_dir / f'design_whisker_combined.pkl')\n",
    "\n",
    "spks = np.load(roi_dir / 'spks_reduced.npy')\n",
    "iscell = np.load(roi_dir / 'iscell.npy')\n",
    "cell_inds = np.where(iscell[:,0]==1)[0]\n",
    "spks = spks[cell_inds,:]\n",
    "norm_spks = (spks - spks.mean(axis=1)[:,np.newaxis]) / spks.std(axis=1)[:,np.newaxis]\n",
    "ophys_frametime = pd.read_pickle(roi_dir / 'refined_frame_time.pkl')\n",
    "assert len(ophys_frametime) == spks.shape[1]\n",
    "\n",
    "# filter out rows from design_df\n",
    "# those with NaN values\n",
    "# those that are not in ophys_frametime (trialNum, frame_index)\n",
    "keep_ind = np.where(np.isnan(np.sum(design_df.values, axis=1).astype(float))==False)[0]\n",
    "filtered_design_df = design_df.iloc[keep_ind]\n",
    "if standardize_features:\n",
    "    feature_namebase_to_standardize = ['touch_count', 'num_lick', 'num_whisks', 'midpoint', 'amplitude']\n",
    "        # Other 11 whisker features are already standardized\n",
    "    feature_names_to_standardize = [design_column for design_column in filtered_design_df.columns if any([namebase in design_column for namebase in feature_namebase_to_standardize])]\n",
    "    for feature_name in feature_names_to_standardize:\n",
    "        design_df[feature_name] = (design_df[feature_name] - design_df[feature_name].mean()) / design_df[feature_name].std()\n",
    "filtered_design_df = filtered_design_df.query('trialNum in @ophys_frametime.trialNum and frame_index in @ophys_frametime.frame_index')\n",
    "filtered_design_df = filtered_design_df.reset_index(drop=True)\n",
    "assert len(filtered_design_df.frame_index.unique()) == len(filtered_design_df)\n",
    "assert np.isin(filtered_design_df.frame_index.values, ophys_frametime.frame_index.values).all()\n",
    "\n",
    "spks_frame_inds = np.where(np.isin(ophys_frametime.frame_index.values, filtered_design_df.frame_index.values))[0]\n",
    "assert len(spks_frame_inds) == len(filtered_design_df)\n",
    "if standardize_traces:\n",
    "    spks = norm_spks\n",
    "traces = spks[:,spks_frame_inds].T \n",
    "# Now traces are in shape of (n_frames, n_cells)\n",
    "\n",
    "# Standardization\n",
    "# No change in touch, lick, reward, sound, num_whisks\n",
    "# Just for amplitude and midpoint\n",
    "standardized_names = [key for key in filtered_design_df.keys() if ('midpoint' in key) or ('amplitude' in key)]\n",
    "for key in standardized_names:\n",
    "    filtered_design_df[key] = (filtered_design_df[key] - filtered_design_df[key].mean()) / filtered_design_df[key].std()\n",
    "\n",
    "# feature names\n",
    "whisker_feature_names_base = ['theta_onset', 'phi_onset', 'kappaH_onset', 'kappaV_onset',\n",
    "    'arc_length_onset', 'touch_count', 'delta_theta', 'delta_phi',\n",
    "    'delta_kappaH', 'delta_kappaV', 'touch_duration', 'slide_distance']\n",
    "whisker_feature_names = [key for key in filtered_design_df.keys() if sum([wfnb in key for wfnb in whisker_feature_names_base])==1]\n",
    "whisking_names = [key for key in filtered_design_df.keys() if ('num_whisks' in key) or ('midpoint' in key) or ('amplitude' in key)]\n",
    "lick_names = [key for key in filtered_design_df.keys() if 'num_lick' in key]\n",
    "sound_names = [key for key in filtered_design_df.keys() if 'pole_in_frame' in key or 'pole_out_frame' in key]\n",
    "reward_names = [key for key in filtered_design_df.keys() if 'first_reward_lick' in key]\n",
    "\n",
    "# Adding the bias column\n",
    "X = np.hstack((np.ones((len(filtered_design_df),1)), filtered_design_df[whisker_feature_names + whisking_names + lick_names + sound_names + reward_names].values)).astype(float)\n",
    "\n",
    "# Turning into xarray\n",
    "x = np.hstack((np.ones((len(filtered_design_df),1)), filtered_design_df[whisker_feature_names + whisking_names + lick_names + sound_names + reward_names].values)).astype(float)\n",
    "X = xr.DataArray(x, dims=('index', 'feature'), \n",
    "                    coords={'index':filtered_design_df.index.values,\n",
    "                            'feature':['intercept'] + whisker_feature_names + whisking_names + lick_names + sound_names + reward_names})\n",
    "traces = xr.DataArray(traces, dims=('index', 'cell_id'),\n",
    "                    coords={'index':filtered_design_df.index.values,\n",
    "                            'cell_id':cell_inds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = filtered_design_df.keys()[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['theta_onset_0',\n",
       " 'theta_onset_1',\n",
       " 'theta_onset_2',\n",
       " 'phi_onset_0',\n",
       " 'phi_onset_1',\n",
       " 'phi_onset_2',\n",
       " 'kappaH_onset_0',\n",
       " 'kappaH_onset_1',\n",
       " 'kappaH_onset_2',\n",
       " 'kappaV_onset_0',\n",
       " 'kappaV_onset_1',\n",
       " 'kappaV_onset_2',\n",
       " 'arc_length_onset_0',\n",
       " 'arc_length_onset_1',\n",
       " 'arc_length_onset_2',\n",
       " 'touch_count_0',\n",
       " 'touch_count_1',\n",
       " 'touch_count_2',\n",
       " 'delta_theta_0',\n",
       " 'delta_theta_1',\n",
       " 'delta_theta_2',\n",
       " 'delta_phi_0',\n",
       " 'delta_phi_1',\n",
       " 'delta_phi_2',\n",
       " 'delta_kappaH_0',\n",
       " 'delta_kappaH_1',\n",
       " 'delta_kappaH_2',\n",
       " 'delta_kappaV_0',\n",
       " 'delta_kappaV_1',\n",
       " 'delta_kappaV_2',\n",
       " 'touch_duration_0',\n",
       " 'touch_duration_1',\n",
       " 'touch_duration_2',\n",
       " 'slide_distance_0',\n",
       " 'slide_distance_1',\n",
       " 'slide_distance_2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisker_feature_names = [key for key in filtered_design_df.keys() if sum([wfnb in key for wfnb in whisker_feature_names_base])==1]\n",
    "whisker_feature_names\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suite2p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
